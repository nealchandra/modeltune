version: "3.8"

services:
  api:
    build: ./llm-api
    ports:
      - 8080:8080
    command: uvicorn main:app --host 0.0.0.0 --port 8080 --reload
    volumes:
      - ./llm-api:/usr/src/app
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis

  gpt:
    build:
      context: ./gpt
      dockerfile: Dockerfile
    image: gpt
    runtime: nvidia
    shm_size: "64gb"
    command: celery --app=worker.celery worker -P solo --loglevel=info
    volumes:
      - ${MODELS_DIR:-../../models}:/usr/models
      - ${DATASETS_DIR:-../../datasets}:/usr/datasets
    ports:
      - 7860:7860
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - CONFIG_PATH=${CONFIG_RELATIVE_PATH}
      - MODEL_PATH=${MODEL_RELATIVE_PATH}
      - LORA_OUTPUT_PATH=${LORA_OUTPUT_RELATIVE_PATH}
      - DATASET_PATH=${DATASET_PATH}
    depends_on:
      - redis

  redis:
    image: redis:6-alpine
